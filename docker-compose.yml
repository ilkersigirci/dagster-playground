version: "3.9"

networks:
  dagster_network:
    driver: bridge
    name: dagster_network

# volumes:
#   postgresql:

x-app-vars:
  &postgres_envs
  DAGSTER_POSTGRES_HOSTNAME: "postgresql"
  DAGSTER_POSTGRES_DB: "postgres_db"
  DAGSTER_POSTGRES_USER: "postgres_user"
  DAGSTER_POSTGRES_PASSWORD: "postgres_password"


services:
  # This service runs the postgres DB used by dagster for run storage, schedule storage,
  # and event log storage.
  postgresql:
    image: postgres:11
    container_name: postgresql
    networks:
      - dagster_network
    environment:
      POSTGRES_DB: postgres_db
      POSTGRES_USER: postgres_user
      POSTGRES_PASSWORD: postgres_password
    # volumes:
    #   - ./postgres-dagster:/var/lib/postgresql/data

  # localstack:
  #   image: localstack/localstack
  #   container_name: localstack
  #   ports:
  #     - "4566:4566"
  #   environment:
  #     HOSTNAME: localhost
  #     SERVICES: s3
  #     AWS_ACCESS_KEY_ID: test
  #     AWS_SECRET_ACCESS_KEY: test
  #     DEFAULT_REGION: us-east-1
  #   volumes:
  #     - ./scripts/local_stack.sh:/docker-entrypoint-initaws.d/create_localstack_infra.sh
  #   networks:
  #     - dagster_network

  # This service runs the gRPC server that loads your user code, in both dagit
  # and dagster-daemon. By setting DAGSTER_CURRENT_IMAGE to its own image, we tell the
  # run launcher to use this same image when launching runs in a new container as well.
  # Multiple containers like this can be deployed separately - each just needs to run on
  # its own port, and have its own entry in the workspace.yaml file that's loaded by dagit.
  user-code:
    build:
      context: .
      dockerfile: ./docker/Dockerfile_user_code
      # target: data-analytics
    container_name: user-code
    restart: always
    # depends_on:
      # - localstack
      # - postgresql  # TODO: Is needed?
    networks:
      - dagster_network
    # profiles:
    #   - dagster
    environment:
      << : *postgres_envs
      # Keys for localstack
      AWS_ACCESS_KEY_ID: test
      AWS_SECRET_ACCESS_KEY: test
    # volumes:
    #   - ./dagster_playground:/opt/dagster/dagster_home/app

  # This service runs dagit, which loads your user code from the user code container.
  # Since our instance uses the QueuedRunCoordinator, any runs submitted from dagit will be put on
  # a queue and later dequeued and launched by dagster-daemon.
  dagit:
    build:
      context: .
      dockerfile: ./docker/Dockerfile_dagster
      # target: dagit
    entrypoint:
      - dagit
      - -h
      - "0.0.0.0"
      - -p
      - "3000"
      - -w
      - workspace.yaml
    container_name: dagit
    restart: on-failure
    depends_on:
      - postgresql
      - user-code
    networks:
      - dagster_network
    ports:
      - "3000:3000"
    # profiles:
    #   - dagster
    environment:
      << : *postgres_envs
    # volumes:
    #   - /tmp/io_manager_storage:/tmp/io_manager_storage  # TODO: Is needed?
    #   - ./dagster.yaml:/opt/dagster/dagster_home/dagster.yaml
    #   - ./workspace.yaml:/opt/dagster/dagster_home/workspace.yaml


  # This service runs the dagster-daemon process, which is responsible for taking runs
  # off of the queue and launching them, as well as creating runs from schedules or sensors.
  dagster-daemon:
    build:
      context: .
      dockerfile: ./docker/Dockerfile_dagster
      # target: daemon
    entrypoint:
      - dagster-daemon
      - run
    container_name: dagster-daemon
    restart: on-failure
    depends_on:
      - postgresql
      - user-code
    networks:
      - dagster_network
    # profiles:
    #   - dagster
    environment:
      << : *postgres_envs
    # volumes:
    #   - /tmp/io_manager_storage:/tmp/io_manager_storage  # TODO: Is needed?
    #   - ./dagster.yaml:/opt/dagster/dagster_home/dagster.yaml
    #   - ./workspace.yaml:/opt/dagster/dagster_home/workspace.yaml
